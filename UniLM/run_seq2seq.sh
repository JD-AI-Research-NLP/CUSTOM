# CUDA_VISIBLE_DEVICES=0,1,2,3 python3 -m torch.distributed.launch --nproc_per_node=4 run_seq2seq.py --data_dir ./data/shouji/ --src_file train.input --tgt_file train.target --src_file_dev dev.input --tgt_file_dev dev.target --model_type unilm --model_name_or_path ./pretrained_model/ --output_dir ./finetuned_model/shouji_testdev/ --max_seq_length 512 --max_position_embeddings 512 --do_train --do_lower_case --train_batch_size 32 --learning_rate 1e-5 --num_train_epochs 20

CUDA_VISIBLE_DEVICES=0,1,2,3 python3 -m torch.distributed.launch --nproc_per_node=4 run_seq2seq.py --data_dir ./data/shouji/ --src_file train.input --tgt_file train.target --asp_file train.aspect --focus_file train.focus --src_file_dev dev.input --tgt_file_dev dev.target --asp_file_dev dev.aspect --focus_file_dev dev.focus --model_type unilm --model_name_or_path ./pretrained_model/ --output_dir ./finetuned_model/shouji/ --log_dir ./log/shouji --max_seq_length 512 --max_position_embeddings 512 --do_train --do_lower_case --train_batch_size 20 --learning_rate 1e-5 --num_train_epochs 30